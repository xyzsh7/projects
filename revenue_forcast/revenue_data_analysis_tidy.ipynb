{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e4f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed9f815",
   "metadata": {},
   "source": [
    "## Read and Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff372515",
   "metadata": {},
   "source": [
    "##### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2ad0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() # get the current directory where the script is placed\n",
    "path_f = f'{path}\\\\input_source_file.xlsx'\n",
    "path_r = f'{path}\\\\input_ref_file.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95687637",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.read_excel(path_f,\n",
    "                          sheet_name=\"DataTable\",\n",
    "                          dtype={'Ship To ID':str,\n",
    "                          'Order Date':'datetime64[ns]'})  #read table autochem extract for bryan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c999ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for each sheets in files\n",
    "ptlist = pd.read_excel(path_r, sheet_name=\"allparts\", na_values=['None'],dtype={'MTPN':str,'Associated Site Part to Increment':str})  #read partlists table\n",
    "ctryrep = pd.read_excel(path_r, sheet_name=\"CountryNameRep\",keep_default_na=False)  #read country name representation table and keep auto-detecting na function off (NA:north america)\n",
    "region = pd.read_excel(path_r,sheet_name=\"Region\",na_values=[\"N/A\", \"#N/A\"],keep_default_na=False)  #read region table\n",
    "id = pd.read_excel(path_r,sheet_name='SiteNames',dtype={'Ship-To Party':str}).rename({'Ship-To Party':'Ship To ID','Site Name':'Customer'},axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d5ab1",
   "metadata": {},
   "source": [
    "##### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e327cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "id['Ship To ID'] = id['Ship To ID'].apply(lambda x: x.lstrip('0'))  #force column type to eliminate leading zeros then to str\n",
    "full_data['Ship To ID'] = full_data['Ship To ID'].apply(lambda x: x.lstrip('0'))  #strip leading zeros\n",
    "\n",
    "#select needed columns from full data and rename\n",
    "sub_data = full_data[[\n",
    "    'Geo Country', 'Sales Org', 'Model ID', 'Model', 'SVC Mat ID',\n",
    "    'Material ID', 'Material', 'Product Type', 'Order Number',\n",
    "    'Sold To Customer ID', 'Sold To Customer', 'Ship To ID',\n",
    "    'Ship To Customer', 'Ship To Country', 'Industry Level 1 - Ship to',\n",
    "    'Industry Level 2 - Ship to', 'Order Date', 'Month', 'Quarter',\n",
    "    'List Price', 'Net Sales', 'Quantity']].copy().rename({'Material ID': 'MTPN'},axis=1)\n",
    "\n",
    "#split qtr col to two called quarter&yr_ordered\n",
    "sub_data[['Quarter', 'Yr_ordered']] = sub_data.Quarter.str.split(' ', expand=True)\n",
    "sub_data['Quarter'] = sub_data['Quarter'].replace('Q4','Q0')  #replace Q4 with Q0\n",
    "sub_data['Yr_ordered'] = sub_data['Yr_ordered'].astype(int)  #se the yr col type to int\n",
    "\n",
    "#save year as int type and assign to a new column Year Alloc and assign Q0 to the next year\n",
    "sub_data['Yr_alloc'] = sub_data['Yr_ordered'].mask(sub_data['Quarter'] == 'Q0',sub_data['Yr_ordered'] + 1)\n",
    "\n",
    "#create a new country column with fixed country names\n",
    "sub_data['Country'] = sub_data['Ship To Country'].replace(ctryrep['Bad Name'].tolist(), ctryrep['Rename'].tolist())\n",
    "sub_data = sub_data.merge(region, on='Country',how='left')  #add region column\n",
    "#sub_data[['Region', 'Country']].value_counts() # check data\n",
    "\n",
    "sub_data['unitLP'] = sub_data['List Price'] / sub_data['Quantity']  #create a unitLP column\n",
    "sub_data['discount'] = sub_data['Net Sales'] / sub_data['List Price']  #create a discount column\n",
    "#sub_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd1b94",
   "metadata": {},
   "source": [
    "##### HW and SL List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca3f4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sitelist of category in Site lisc\n",
    "hwlist = ptlist[ptlist['Category'] == 'Hardware'].reset_index(drop=True)\n",
    "#hwlist = hwlist.rename({'MTPN':'SVC Mat ID'},axis=1) #rename material ID to MTPN for inner join\n",
    "sitelist = ptlist[ptlist['Category'] == 'Site'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04082c1",
   "metadata": {},
   "source": [
    "##### Customer Name and expiration List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35dea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read current SL cus datafile and rename the column\n",
    "slcus_exp = pd.read_excel(path_r, sheet_name='SL_exp', dtype = {'SL_exp_dt': 'datetime64[ns]'})\\\n",
    "              .rename({'Name': 'Customer','SL Expiration Date': 'SL_exp_dt'}, axis=1)  \n",
    "for row, col in slcus_exp.iterrows(): # ** made change here so the contract length is showing as numerical and future changes will be automated\n",
    "    for x in col:\n",
    "        slcus_exp.loc[row, \"contract_start\"] = col['SL_exp_dt'] - pd.DateOffset(years= int(col['Contract Length'].split()[0]))\n",
    "slcus_exp_id = pd.merge(slcus_exp,id[['Ship To ID','Customer']],on='Customer',how='inner') # match and merge SiteName and SL_exp sheets \n",
    "\n",
    "#slcus_exp.head()\n",
    "#slcus_exp_id.head()\n",
    "\n",
    "#pd.merge(slcus_exp,id,on='Customer',how='outer',indicator=True).query('_merge == \"right_only\"') # checking SiteNames and SL_exp sheets where doesnt match (expired customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39f908",
   "metadata": {},
   "source": [
    "-----\n",
    "## SL Data Processing\n",
    "* Get all the SL orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09194d19",
   "metadata": {},
   "source": [
    "##### SL data and Customer Contract List and Get aggregated active Customers SL orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8171aa9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#inner join two dataframe by MTPN to get all the SL orders\n",
    "sl_orders = pd.merge(sub_data, sitelist, on='MTPN', how='inner')\n",
    "sl_orders = sl_orders.drop(sl_orders[sl_orders['Quantity'] == 0].index) #data check --> subset where quantity = 0 and drop rows\n",
    "sl_orders.isna().sum() #check NA rows/ get na order numbers\n",
    "#site_data.info()\n",
    "\n",
    "# merge with ship to id sheet to match and get the active SL orders\n",
    "# define a function and call to generate orders that include expiration date info\n",
    "def get_fullsl(all_sl_orders):\n",
    "    order_exp = pd.merge(all_sl_orders, slcus_exp_id, on='Ship To ID', how='inner') # merge to get the matching records on both sheets\n",
    "    con = ((order_exp['contract_start'] - pd.DateOffset(months=3)) < order_exp['Month']) & ((order_exp['Month'] <= order_exp['SL_exp_dt'].dt.to_period('M'))) # set a condition\n",
    "    order_exp = order_exp[con == True].reset_index(drop=True) # select condition in the merged sl order sheet: order_exp\n",
    "    \n",
    "    #generate aggregated SL orders that ordered within their current term\n",
    "    orders = order_exp[[\n",
    "        'Customer', 'MTPN', 'unitLP', 'SPG', 'SubCat', 'Country', 'Region',\n",
    "        'Order Date', 'Contract Length', 'discount', 'Net Sales', 'SL_exp_dt',\n",
    "        'Quantity'\n",
    "    ]].rename({'Quantity': 'SL_quant'}, axis=1) # select needed columns and rename Quantity\n",
    "    uniq_MTPN = order_exp.groupby(['Customer'])['MTPN'].unique().explode() #get the unique MTPN list of SL purchased by each customer\n",
    "    # merge to get unique MTPN list ordered by each customer\n",
    "    uniq_MTPN = pd.merge(orders,uniq_MTPN, on=['Customer', 'MTPN'], how='inner')\n",
    "    # group and aggregate to get mean net sales/dis for each subCat and maximum purchased quanity of each device under SubCat\n",
    "    agg_orders = uniq_MTPN.groupby(['Customer', 'MTPN', 'SPG', 'SubCat', 'Contract Length',\n",
    "                        'Country','Region', 'SL_exp_dt']).agg({'SL_quant': 'max','unitLP': 'mean',\n",
    "                        'Net Sales': 'mean','discount': 'mean'}).sort_values(by=['Customer', 'MTPN']).reset_index()\n",
    "    return order_exp, agg_orders\n",
    "sheets = get_fullsl(sl_orders)\n",
    "\n",
    "sl_orders_exp = sheets[0] # subset 1st sheet and call it \n",
    "agg_sl_orders = sheets[1] # subset 2nd sheet and call it \n",
    "\n",
    "#sl_orders_exp.head()\n",
    "#agg_sl_orders.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0808f7a",
   "metadata": {},
   "source": [
    "----\n",
    "## Hardware Data\n",
    "* Get all the HW orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41be0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the hardwares that are associated with Site License\n",
    "hw_orders = pd.merge(sub_data, hwlist, on='MTPN', how='inner')\\\n",
    "              .rename({'Associated Site Part to Increment': 'SL_MTPN', 'Quantity': 'HW_quant'}, axis=1)\\\n",
    "              .dropna(subset=['SL_MTPN'])  # merge, rename, dropna of 'SL_MTPN' column\n",
    "#hw_orders.info()\n",
    "\n",
    "# define and call function to get hw orders\n",
    "def get_hworder(cus_exp_data):\n",
    "    active_hw = pd.merge(cus_exp_data, hw_orders, on='Ship To ID', how='inner')  # get hw data based on customer contract yr\n",
    "    active_hw = active_hw[[\n",
    "        'Customer','Country', 'Description', 'Contract Length', 'SL_exp_dt', 'contract_start',\n",
    "        'SubCat', 'Order Number', 'License Desc', 'SL_MTPN', 'Order Date','HW_quant']] #subset these columns\n",
    "    order_con = (active_hw['contract_start'] < active_hw['Order Date']) & (active_hw['Order Date'] <= (active_hw['SL_exp_dt']))# save only the records within 3 yr contract period\n",
    "    active_hw = active_hw[order_con] #subset rows where condition is true\n",
    "    # group by these columns and aggregate by the sum of hardware quantity and rename\n",
    "    active_hw = active_hw.groupby(['Customer', 'SL_MTPN', 'SubCat',\n",
    "                            'Country', 'Order Date','Order Number']).agg({'HW_quant': 'sum'}).reset_index()\\\n",
    "                         .rename({'Order Date': 'hw_order_dt'}, axis=1) \n",
    "    active_hw['hw_order_yr'] = active_hw['hw_order_dt'].dt.year #create a new column of ordered year \n",
    "    return active_hw\n",
    "hw_orders_exp = get_hworder(slcus_exp_id)\n",
    "#hw_orders_exp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0808f7a",
   "metadata": {},
   "source": [
    "----\n",
    "## Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec564c0",
   "metadata": {},
   "source": [
    "##### Check possible Missing IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f022ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#orders - check possible missing ship to IDs\n",
    "def get_missing_ids(orders):\n",
    "    missing_ids = pd.merge(id, orders, on='Ship To ID', how='outer', indicator=True)\n",
    "    missing_ids = missing_ids.query('_merge ==  \"right_only\"')[['Model','Sold To Customer','Ship To ID',\n",
    "                                                 'Ship To Customer','Country','Region',\n",
    "                                                 'Order Number','Order Date','SubCat']].value_counts().reset_index().drop_duplicates(subset=['Ship To ID','Country'])\n",
    "    return missing_ids\n",
    "inactive_sl_customers = get_missing_ids(sl_orders)\n",
    "missing_hw_ids = get_missing_ids(hw_orders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec564c0",
   "metadata": {},
   "source": [
    "##### Write to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a31db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('output_sl_hw_details.xlsx',engine='xlsxwriter') as writer:\n",
    "    # Each call to to_excel creates a new sheet in our excel file output.xlsx\n",
    "    sl_orders.to_excel(writer,sheet_name='all_SL Orders',index=False)\n",
    "    agg_sl_orders.to_excel(writer,sheet_name='agg SL Orders',index=False)\n",
    "    hw_orders.to_excel(writer,sheet_name='all_HW_orders',index=False)\n",
    "    hw_orders_exp.to_excel(writer, sheet_name='HW orders assoc SL', index=False)\n",
    "    inactive_sl_customers.to_excel(writer, sheet_name='SL-other IDs', index=False)\n",
    "    missing_hw_ids.to_excel(writer, sheet_name='HW-other IDs', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f9093",
   "metadata": {},
   "source": [
    "----\n",
    "## Forcast\n",
    "To get totalt quantity of SL for calculating the New Quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9601c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and call function to merge to get the quantity change \n",
    "def sl_hw_merge(x, y):\n",
    "    sl_col = ['Customer', 'MTPN', 'Country', 'SubCat']\n",
    "    hw_col = ['Customer', 'SL_MTPN', 'Country', 'SubCat']\n",
    "    qt_change = pd.merge(x, y, how='left', left_on=sl_col, right_on=hw_col).fillna(0)\n",
    "    qt_change['SL_exp_yr'] = qt_change['SL_exp_dt'].dt.year #creating a column of exp yr for comparsion \n",
    "    \n",
    "    #aggregate Hardware quantity\n",
    "    revenue_forcast = qt_change.groupby([\n",
    "    'Customer', 'Region', 'Country', 'SL_exp_dt', 'SL_exp_yr',\n",
    "    'Contract Length', 'SPG', 'SubCat', 'MTPN', 'SL_MTPN', 'unitLP',\n",
    "    'discount', 'Net Sales', 'SL_quant']).agg({'HW_quant': 'sum'}).reset_index() #to aggregate the HW quantity by other others\n",
    "    revenue_forcast['total_qt'] = revenue_forcast['HW_quant'] + revenue_forcast['SL_quant']  #calculate the new quantity\n",
    "    \n",
    "    # create a separate file of cross table of customer names and expiration years\n",
    "    cus = pd.DataFrame(revenue_forcast['Customer'].unique().tolist(), columns=['Customer']) #get the unique list and name it 'Customer'\n",
    "    yr = pd.DataFrame(revenue_forcast['SL_exp_yr'].unique().tolist(), columns=['Year']) #get the unique list of SL exp years and name it 'Year'\n",
    "    cusyr_cross = cus.merge(yr, how='cross').sort_values(by=['Customer', 'Year']).reset_index(drop=True) # merge to get the cross list of customer names and year\n",
    "    return qt_change, revenue_forcast, cusyr_cross\n",
    "sheets = sl_hw_merge(agg_sl_orders,hw_orders_exp)\n",
    "\n",
    "# write to excel file\n",
    "qt_change = sheets[0].to_excel('output_qt_change.xlsx') \n",
    "revenue_forcast = sheets[1].to_excel('output_revenue_forecast.xlsx')\n",
    "cusyr_cross = sheets[2].to_excel('output_CusYr_cross.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
